"""
Code Translator for 6502 Assembly to C++
"""

import os
import re
from typing import Dict, List, Optional, Set
from ast_nodes import *
from tokens import TokenType
from util import lookup_comment

# Tab character used in translation (4 spaces)
TAB = "    "

AUTOGENERATED_FILE_MESSAGE = "// This is an automatically generated file.\n// Do not edit directly.\n//\n"
LINE_SEPARATOR_COMMENT = "//------------------------------------------------------------------------\n"

from typing import Dict, Set, List, Optional
import json
from pathlib import Path

# ADD THESE TWO CLASSES to your translator.py (keep your existing classes too):

class IndirectJumpConfig:
    """Loads and manages indirect jump configuration"""
    
    def __init__(self, config_dir: str = None, is_ca65: bool = False):
        self.config_dir = config_dir
        self.is_ca65 = is_ca65
        self.jump_targets: Dict[str, Dict[str, str]] = {}  # jump_var -> {address: label}
        self.loaded = False
        
        if config_dir:
            self.load_config()
    
    def load_config(self):
        """Load indirect jump configuration from files"""
        if not self.config_dir or not os.path.exists(self.config_dir):
            print(f"Warning: Indirect jump config directory '{self.config_dir}' not found")
            return
        
        # Load individual target files
        self._load_individual_configs()
        
        # Try to load JSON config as backup
        json_config = Path(self.config_dir) / "indirect_jumps.json"
        if json_config.exists():
            self._load_json_config(json_config)
        
        self.loaded = True
        if self.jump_targets:
            print(f"Loaded indirect jump config for {len(self.jump_targets)} variables")
    
    def _load_individual_configs(self):
        """Load individual target configuration files"""
        config_path = Path(self.config_dir)
        
        for config_file in config_path.glob("*_targets.txt"):
            self._load_target_file(config_file)
    
    def _load_target_file(self, config_file: Path):
        """Load a single target configuration file"""
        try:
            # Extract jump variable name from filename
            filename = config_file.stem
            if filename.endswith("_targets"):
                var_name = filename[:-8]  # Remove "_targets"
                
                # Convert filename back to variable name
                if var_name.startswith("var_"):
                    jump_var = "_" + var_name  # _var_0610
                else:
                    jump_var = var_name
                
                if jump_var not in self.jump_targets:
                    self.jump_targets[jump_var] = {}
                
                with open(config_file, 'r') as f:
                    for line_num, line in enumerate(f, 1):
                        line = line.strip()
                        
                        # Skip comments and empty lines
                        if not line or line.startswith('#'):
                            continue
                        
                        # Parse ADDRESS:LABEL format
                        if ':' in line:
                            parts = line.split(':', 1)
                            if len(parts) == 2:
                                address = parts[0].strip().upper()
                                label = parts[1].strip()
                                self.jump_targets[jump_var][address] = label
                                print(f"  Loaded target: {jump_var} -> 0x{address} = {label}")
                        else:
                            print(f"Warning: Invalid format in {config_file} line {line_num}: {line}")
        
        except Exception as e:
            print(f"Warning: Could not load {config_file}: {e}")
    
    def _load_json_config(self, config_file: Path):
        """Load JSON configuration file as backup"""
        try:
            with open(config_file, 'r') as f:
                data = json.load(f)
            
            for jump_var, config in data.items():
                if jump_var not in self.jump_targets:
                    self.jump_targets[jump_var] = {}
                
                # Load resolved targets
                if "resolved_targets" in config:
                    for target, label in config["resolved_targets"].items():
                        if not target.startswith(("LABEL:", "TABLE:")) and label != "NEEDS_MANUAL_ANALYSIS":
                            if target not in self.jump_targets[jump_var]:
                                self.jump_targets[jump_var][target] = label
        except Exception as e:
            print(f"Warning: Could not load JSON config: {e}")
    
    def get_targets(self, jump_var: str) -> Dict[str, str]:
        """Get all targets for a jump variable with format-specific matching"""
        # Try exact match first
        if jump_var in self.jump_targets:
            return self.jump_targets[jump_var]
        
        # Format-specific variations
        variations = []
        
        if self.is_ca65:
            # CA65 format variations
            variations = [
                jump_var.replace('z:', ''),
                jump_var.replace('(', '').replace(')', ''),
                '_' + jump_var if not jump_var.startswith('_') else jump_var[1:],
                jump_var.replace('_var_', ''),
                jump_var.replace('_indexed', ''),
            ]
        else:
            # Original format variations
            variations = [
                jump_var.replace('*', ''),
                jump_var.replace('label*', ''),
                jump_var.replace(':', ''),
                '_var_' + jump_var if not jump_var.startswith('_var_') else jump_var,
                jump_var.replace('_indexed', ''),
            ]
        
        for var in variations:
            if var in self.jump_targets:
                return self.jump_targets[var]
        
        # Try partial matches
        for var_key in self.jump_targets.keys():
            if jump_var in var_key or var_key in jump_var:
                return self.jump_targets[var_key]
        
        return {}
    
    def has_targets(self, jump_var: str) -> bool:
        """Check if we have targets configured for a jump variable"""
        return len(self.get_targets(jump_var)) > 0


class IndirectJumpTranslator:
    """Handles translation of indirect jumps to switch statements"""
    
    def __init__(self, translator_instance):
        self.translator = translator_instance
        self.config = IndirectJumpConfig(
            translator_instance.config_dir, 
            getattr(translator_instance, 'is_ca65', False)
        )
    
    def translate_indirect_jump(self, instruction) -> str:
        """Translate JMP (variable) to switch statement"""
        if not hasattr(instruction, 'value') or not instruction.value:
            return "/* indirect jump - no operand */"
        
        # Extract jump variable from operand
        jump_var = self._extract_jump_variable(instruction.value)
        if not jump_var:
            return f"/* indirect jump - could not parse operand */"
        
        # Get configured targets
        targets = self.config.get_targets(jump_var)
        if not targets:
            return self._generate_fallback_jump(jump_var)
        
        # Generate switch statement
        return self._generate_switch_statement(jump_var, targets)
    
    def _extract_jump_variable(self, operand) -> str:
        """Extract variable name from JMP operand"""
        # Handle different operand types from your AST
        if hasattr(operand, 'child') and hasattr(operand.child, 'value'):
            return operand.child.value
        elif hasattr(operand, 'value'):
            return operand.value
        elif isinstance(operand, str):
            return operand
        else:
            return str(operand)
    
    def _generate_switch_statement(self, jump_var: str, targets: Dict[str, str]) -> str:
        """Generate switch statement for indirect jump"""
        result = f"// Indirect jump through {jump_var}\n"
        result += f"{TAB}switch (W({jump_var})) {{\n"
        
        for address, label in sorted(targets.items()):
            result += f"{TAB}case 0x{address}:\n"
            result += f"{TAB}{TAB}goto {label};\n"
        
        result += f"{TAB}default:\n"
        result += f"{TAB}{TAB}// Unknown jump target in {jump_var}\n"
        result += f"{TAB}{TAB}return; // or handle error\n"
        result += f"{TAB}}}"
        
        return result
    
    def _generate_fallback_jump(self, jump_var: str) -> str:
        """Generate fallback code when no targets are configured"""
        analyzer_script = "ca65_analyzer.py" if self.config.is_ca65 else "rom_analyzer.py"
        
        return f"""// Indirect jump through {jump_var} - NO TARGETS CONFIGURED
{TAB}// Run: python {analyzer_script} input.asm to detect targets
{TAB}switch (W({jump_var})) {{
{TAB}default:
{TAB}{TAB}// Add targets to {self.config.config_dir or 'config'}/{jump_var.replace(':', '_')}_targets.txt
{TAB}{TAB}return;
{TAB}}}"""

class FirstPassClassifier:
    """First pass classifier to determine label types from assembly text"""
    
    def __init__(self, assembly_text: str, config_dir: str = None):
        self.assembly_text = assembly_text
        self.lines = assembly_text.split('\n')
        self.labels: Dict[str, LabelType] = {}
        self.label_line_map: Dict[str, int] = {}
        self.data_indicators = {'.db', '.dw', '.byte', '.word'}
        self.instruction_keywords = self._get_6502_instructions()
        
        # Load label classifications from config files
        self.forced_data_labels = set()
        self.forced_code_labels = set()
        self.forced_alias_labels = set()
        
        if config_dir:
            self._load_label_config(config_dir)
    
    def _load_label_config(self, config_dir: str):
        """Load label classification from config files"""
        import os
        
        # Load forced data labels
        data_file = os.path.join(config_dir, "data_labels.txt")
        if os.path.exists(data_file):
            try:
                with open(data_file, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            self.forced_data_labels.add(line)
                print(f"Loaded {len(self.forced_data_labels)} forced DATA labels from {data_file}")
            except Exception as e:
                print(f"Warning: Could not load {data_file}: {e}")
        
        # Load forced code labels
        code_file = os.path.join(config_dir, "code_labels.txt")
        if os.path.exists(code_file):
            try:
                with open(code_file, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            self.forced_code_labels.add(line)
                print(f"Loaded {len(self.forced_code_labels)} forced CODE labels from {code_file}")
            except Exception as e:
                print(f"Warning: Could not load {code_file}: {e}")
        
        # Load forced alias labels
        alias_file = os.path.join(config_dir, "alias_labels.txt")
        if os.path.exists(alias_file):
            try:
                with open(alias_file, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            self.forced_alias_labels.add(line)
                print(f"Loaded {len(self.forced_alias_labels)} forced ALIAS labels from {alias_file}")
            except Exception as e:
                print(f"Warning: Could not load {alias_file}: {e}")
    
    def create_default_config_files(self, config_dir: str):
        """Create default configuration files with examples and detected conflicts"""
        import os
        os.makedirs(config_dir, exist_ok=True)
        
        # Create data_labels.txt only if it doesn't exist
        data_file = os.path.join(config_dir, "data_labels.txt")
        if not os.path.exists(data_file):
            with open(data_file, 'w') as f:
                f.write("# Data Labels Configuration\n")
                f.write("# One label per line - these labels will be treated as DATA (generate pointers)\n")
                f.write("# Lines starting with # are comments\n")
                f.write("#\n")
                f.write("# Examples of typical data labels:\n")
                f.write("# GameText\n")
                f.write("# AreaAddrOffsets\n")
                f.write("# MusicData\n")
                f.write("# PaletteData\n")
                f.write("#\n")
                f.write("# Add labels here that contain lookup tables, graphics data, etc.\n")
            print(f"Created {data_file}")
        
        # Create code_labels.txt only if it doesn't exist
        code_file = os.path.join(config_dir, "code_labels.txt")
        if not os.path.exists(code_file):
            with open(code_file, 'w') as f:
                f.write("# Code Labels Configuration\n")
                f.write("# One label per line - these labels will be treated as CODE (for goto statements)\n")
                f.write("# Lines starting with # are comments\n")
                f.write("#\n")
                f.write("# Add labels here that are used in goto statements but might be misclassified\n")
                f.write("# Common examples from compilation errors:\n")
                f.write("MoveSubs\n")
                f.write("BlockCode\n")
                f.write("JmpEO\n")
                f.write("ExScrnBd\n")
                f.write("MoveAllSpritesOffscreen\n")
                f.write("GetBlockBufferAddr\n")
                f.write("MovePlatformDown\n")
                f.write("PositionPlayerOnS_Plat\n")
                f.write("BlockBufferColli_Head\n")
                f.write("RetYC\n")
                f.write("SetHFAt\n")
            print(f"Created {code_file}")
        
        # Create alias_labels.txt only if it doesn't exist
        alias_file = os.path.join(config_dir, "alias_labels.txt")
        if not os.path.exists(alias_file):
            with open(alias_file, 'w') as f:
                f.write("# Alias Labels Configuration\n")
                f.write("# One label per line - these labels will be treated as ALIAS\n")
                f.write("# Lines starting with # are comments\n")
                f.write("#\n")
                f.write("# Add labels here that are simple aliases to other labels\n")
                f.write("# (Usually labels that just contain 'jmp SomeOtherLabel')\n")
            print(f"Created {alias_file}")
        
        if any(not os.path.exists(f) for f in [data_file, code_file, alias_file]):
            print(f"Config files are in {config_dir}")
            print("Edit these files to fix label classification issues:")
            print(f"  - {data_file}")
            print(f"  - {code_file}")
            print(f"  - {alias_file}")
    
    def _get_6502_instructions(self) -> Set[str]:
        """Get set of all 6502 instruction mnemonics"""
        return {
            'lda', 'ldx', 'ldy', 'sta', 'stx', 'sty',
            'tax', 'tay', 'txa', 'tya', 'tsx', 'txs',
            'pha', 'php', 'pla', 'plp',
            'and', 'eor', 'ora', 'bit',
            'adc', 'sbc', 'cmp', 'cpx', 'cpy',
            'inc', 'inx', 'iny', 'dec', 'dex', 'dey',
            'asl', 'lsr', 'rol', 'ror',
            'jmp', 'jsr', 'rts', 'rti',
            'bcc', 'bcs', 'beq', 'bmi', 'bne', 'bpl', 'bvc', 'bvs',
            'clc', 'cld', 'cli', 'clv', 'sec', 'sed', 'sei',
            'brk', 'nop'
        }
    
    def classify_all_labels(self) -> Dict[str, LabelType]:
        """Perform first pass classification of all labels"""
        # First, find all labels and their locations
        self._find_all_labels()
        
        # Then classify each label based on what follows it
        for label_name, line_num in self.label_line_map.items():
            self.labels[label_name] = self._classify_single_label(label_name, line_num)
        
        return self.labels
    
    def _find_all_labels(self):
        """Find all labels in the assembly code"""
        label_pattern = re.compile(r'^([a-zA-Z_][a-zA-Z0-9_]*):')
        
        for line_num, line in enumerate(self.lines):
            line = line.strip()
            match = label_pattern.match(line)
            if match:
                label_name = match.group(1)
                self.label_line_map[label_name] = line_num
    
    def _classify_single_label(self, label_name: str, start_line: int) -> LabelType:
        """Classify a single label based on what follows it"""
        # Check forced classifications first
        if label_name in self.forced_data_labels:
            return LabelType.LABEL_DATA
        elif label_name in self.forced_code_labels:
            return LabelType.LABEL_CODE
        elif label_name in self.forced_alias_labels:
            return LabelType.LABEL_ALIAS
        
        # Fall back to automatic analysis
        content_analysis = self._analyze_content_after_label(start_line)
        
        # Very strict criteria for DATA classification to prevent goto conflicts
        if (content_analysis['has_data_directives'] and 
            not content_analysis['has_instructions'] and
            content_analysis['only_data_directives'] and
            content_analysis['line_count_analyzed'] >= 3):  # Must have multiple data lines
            return LabelType.LABEL_DATA
        
        # Check for simple aliases (labels that just point to other labels)
        elif (content_analysis['points_to_other_label'] and 
              not content_analysis['has_data_directives'] and
              not content_analysis['has_instructions']):
            return LabelType.LABEL_ALIAS
        
        # Everything else is CODE (safer for goto statements)
        else:
            return LabelType.LABEL_CODE
    
    def _analyze_content_after_label(self, start_line: int) -> Dict[str, bool]:
        """Analyze content following a label to determine its type"""
        analysis = {
            'has_instructions': False,
            'has_data_directives': False,
            'points_to_other_label': False,
            'line_count_analyzed': 0,
            'only_data_directives': True
        }
        
        # Look at up to 30 lines after the label to get better coverage
        max_lines_to_check = min(30, len(self.lines) - start_line - 1)
        content_lines = 0  # Count actual content lines (not empty/comments)
        
        for i in range(1, max_lines_to_check + 1):
            line_num = start_line + i
            if line_num >= len(self.lines):
                break
                
            line = self.lines[line_num].strip()
            
            # Skip empty lines and comments
            if not line or line.startswith(';'):
                continue
            
            # If we hit another label, stop analyzing
            if re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*:', line):
                break
            
            content_lines += 1
            analysis['line_count_analyzed'] = content_lines
            
            # Check for data directives
            if self._line_contains_data_directive(line):
                analysis['has_data_directives'] = True
            else:
                analysis['only_data_directives'] = False
            
            # Check for instructions (this has highest priority)
            if self._line_contains_instruction(line):
                analysis['has_instructions'] = True
                analysis['only_data_directives'] = False
                # Found instruction - definitely code, can stop here
                break
            
            # Check if it points to another label
            if self._line_points_to_label(line):
                analysis['points_to_other_label'] = True
                analysis['only_data_directives'] = False
        
        return analysis
    
    def _line_contains_data_directive(self, line: str) -> bool:
        """Check if line contains data directive like .db or .dw"""
        # Remove comments
        line = line.split(';')[0].strip()
        
        # Check for data directives
        tokens = line.lower().split()
        if tokens and tokens[0] in self.data_indicators:
            return True
        
        return False
    
    def _line_contains_instruction(self, line: str) -> bool:
        """Check if line contains a 6502 instruction"""
        # Remove comments
        line = line.split(';')[0].strip()
        
        # Extract the first token (should be instruction)
        tokens = line.lower().split()
        if tokens and tokens[0] in self.instruction_keywords:
            return True
        
        return False
    
    def _line_points_to_label(self, line: str) -> bool:
        """Simple heuristic to check if line points to another label"""
        # This is a simple check - could be made more sophisticated
        line = line.split(';')[0].strip()
        
        # Look for patterns like "jmp LabelName" or "jsr LabelName"
        tokens = line.lower().split()
        if len(tokens) >= 2 and tokens[0] in ['jmp', 'jsr']:
            target = tokens[1]
            # Check if target looks like a label (not a hex address, etc.)
            if re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', target):
                return True
        
        return False

class Translator:
    def __init__(self, input_filename: str, ast_root_node: RootNode, config_dir: str = None, is_ca65: bool = False):
        self.input_filename = input_filename
        self.root = ast_root_node
        self.return_label_index = 0
        self.skip_next_instruction = False
        self.skip_next_instruction_index = 0
        self.config_dir = config_dir
        self.is_ca65 = is_ca65
        self.indirect_jump_translator = IndirectJumpTranslator(self)

        # First pass classification from source text
        self.first_pass_classifications = {}
        try:
            with open(input_filename, 'r') as f:
                source_text = f.read()
            classifier = FirstPassClassifier(source_text, config_dir)
            self.first_pass_classifications = classifier.classify_all_labels()
            print(f"First pass classified {len(self.first_pass_classifications)} labels")
            
            # Create default config files if they don't exist
            if config_dir:
                classifier.create_default_config_files(config_dir)
                
        except Exception as e:
            print(f"Warning: Could not perform first pass classification: {e}")
        
        # Output streams
        self.source_output = ""
        self.constant_header_output = ""
        self.data_header_output = ""
        self.data_output = ""
        
        # Add headers
        self.source_output += AUTOGENERATED_FILE_MESSAGE
        self.constant_header_output += AUTOGENERATED_FILE_MESSAGE
        self.data_header_output += AUTOGENERATED_FILE_MESSAGE
        self.data_output += AUTOGENERATED_FILE_MESSAGE
        
        self.translate()
    
    def get_constant_header_output(self) -> str:
        return self.constant_header_output
    
    def get_data_output(self) -> str:
        return self.data_output
    
    def get_data_header_output(self) -> str:
        return self.data_header_output
    
    def get_source_output(self) -> str:
        return self.source_output
    
    def classify_labels(self):
        """Classify labels as code, data, or alias using first pass + AST analysis"""
        print("Classifying labels using first pass + AST analysis...")
        
        # Debug: Show some first pass results
        print(f"First pass found {len(self.first_pass_classifications)} labels")
        code_count = sum(1 for t in self.first_pass_classifications.values() if t == LabelType.LABEL_CODE)
        data_count = sum(1 for t in self.first_pass_classifications.values() if t == LabelType.LABEL_DATA)
        alias_count = sum(1 for t in self.first_pass_classifications.values() if t == LabelType.LABEL_ALIAS)
        print(f"First pass classification: {code_count} CODE, {data_count} DATA, {alias_count} ALIAS")
        
        i = 0
        while i < len(self.root.children):
            node = self.root.children[i]
            if node.type != AstType.AST_LABEL:
                i += 1
                continue
            
            label = node
            
            # Handle nested labels (aliases)
            while True:
                child = label.child
                
                if child and child.type == AstType.AST_LABEL:
                    # Nested label - classify as alias and promote child
                    label.label_type = LabelType.LABEL_ALIAS
                    
                    # Promote the nested label to root level
                    self.root.children.insert(i + 1, child)
                    child.parent = self.root
                    
                    label = child
                else:
                    break
            
            # Use first pass classification if available, otherwise analyze AST
            label_name = label.value.rstrip(':')
            if label_name in self.first_pass_classifications:
                label.label_type = self.first_pass_classifications[label_name]
                if label.label_type == LabelType.LABEL_DATA:
                    print(f"  {label.value} -> {label.label_type.name} (first pass - DATA)")
            else:
                # Fall back to AST analysis
                label.label_type = self.analyze_label_content_ast(label)
                print(f"  {label.value} -> {label.label_type.name} (AST fallback)")
            
            i += 1
    
    def analyze_label_content_ast(self, label) -> LabelType:
        """Analyze label content using AST to determine if it's code or data"""
        child = label.child
        
        if not child:
            return LabelType.LABEL_CODE
        
        if child.type == AstType.AST_LABEL:
            # This is an alias - check what it points to
            return LabelType.LABEL_ALIAS
        
        if child.type == AstType.AST_LIST:
            # Examine all items in the list to determine the predominant type
            has_instructions = False
            has_data = False
            
            current_list = child
            while current_list:
                list_element = current_list.value
                if list_element:
                    if list_element.type == AstType.AST_INSTRUCTION:
                        has_instructions = True
                    elif list_element.type in [AstType.AST_DATA8, AstType.AST_DATA16]:
                        has_data = True
                
                current_list = current_list.next
            
            # Determine label type based on content
            if has_data and not has_instructions:
                return LabelType.LABEL_DATA
            else:
                # Default to code if it has instructions or mixed content
                return LabelType.LABEL_CODE
        
        # Default case
        return LabelType.LABEL_CODE
    
    def generate_code(self):
        """Generate the main C++ code with CA65-aware vector names"""
        
        # Use different entry point names based on format
        if self.is_ca65:
            reset_label = "Reset"
            nmi_label = "NMI"
        else:
            reset_label = "Start"
            nmi_label = "NonMaskableInterrupt"
        
        self.source_output += (
            "void SMBEngine::code(int mode)\n"
            "{\n"
            f"{TAB}switch (mode)\n"
            f"{TAB}{{\n"
            f"{TAB}case 0:\n"
            f"{TAB}{TAB}loadConstantData();\n"
            f"{TAB}{TAB}goto {reset_label};\n"
            f"{TAB}case 1:\n"
            f"{TAB}{TAB}goto {nmi_label};\n"
            f"{TAB}}}\n\n"
        )
        
        # Generate code for each code label
        for node in self.root.children:
            if node.type != AstType.AST_LABEL:
                continue
            
            label = node
            if label.label_type != LabelType.LABEL_CODE:
                continue
            
            # Output C++ label
            self.source_output += f"\n{label.value}"
            
            # Add comment if available
            if label.line_number != 0:
                comment = lookup_comment(label.line_number)
                if comment:
                    self.source_output += f" // {comment[1:]}"  # Skip ';'
            
            self.source_output += "\n"
            
            # Translate each instruction in the label
            list_element = label.child
            while list_element is not None:
                instruction = list_element.value
                if instruction.type == AstType.AST_INSTRUCTION:
                    # Set parent reference for JSR JumpEngine handling
                    instruction.parent = list_element
                    
                    translated = self.translate_instruction(instruction)
                    self.source_output += f"{TAB}{translated}"
                    
                    if instruction.line_number != 0:
                        comment = lookup_comment(instruction.line_number)
                        if comment:
                            self.source_output += f" // {comment[1:]}"  # Skip ';'
                    
                    # Add line separator after return statements
                    if instruction.code == TokenType.RTS.value:
                        self.source_output += f"\n\n{LINE_SEPARATOR_COMMENT}"
                    else:
                        self.source_output += "\n"
                    
                    if self.skip_next_instruction:
                        # Add skip label for .db $2c handling
                        self.source_output += f"Skip_{self.skip_next_instruction_index}:\n"
                        self.skip_next_instruction_index += 1
                        self.skip_next_instruction = False
                
                elif (instruction.type == AstType.AST_DATA8 and 
                      hasattr(instruction, 'value') and
                      hasattr(instruction.value, 'value') and
                      hasattr(instruction.value.value, 'value') and
                      instruction.value.value.value == "$2c"):
                    # Special case: .db $2c generates a goto
                    self.skip_next_instruction = True
                    self.source_output += f"{TAB}goto Skip_{self.skip_next_instruction_index};\n"
                
                list_element = list_element.next
        
        # Generate return jump table
        self.source_output += (
            "// Return handler\n"
            "// This emulates the RTS instruction using a generated jump table\n"
            "//\n"
            "Return:\n"
            f"{TAB}switch (popReturnIndex())\n"
            f"{TAB}{{\n"
        )
        
        for i in range(self.return_label_index):
            self.source_output += (
                f"{TAB}case {i}:\n"
                f"{TAB}{TAB}goto Return_{i};\n"
            )
        
        self.source_output += f"{TAB}}}\n"
        self.source_output += "}\n"
    
    def generate_constant_declarations(self):
        """Generate constant declarations header"""
        self.constant_header_output += (
            "#ifndef SMBCONSTANTS_HPP\n"
            "#define SMBCONSTANTS_HPP\n\n"
        )
        
        for node in self.root.children:
            if node.type != AstType.AST_DECL:
                continue
            
            decl = node
            self.constant_header_output += f"#define {decl.value} {self.translate_expression(decl.expression)}"
            
            if decl.line_number != 0:
                comment = lookup_comment(decl.line_number)
                if comment:
                    self.constant_header_output += f" // {comment[1:]}"  # Strip ';'
            
            self.constant_header_output += "\n"
        
        self.constant_header_output += "\n#endif // SMBCONSTANTS_HPP\n"
    
    def generate_data_declarations(self):
        """Generate data declarations and loading code"""
        # Data structure for addresses
        addresses = (
            "// Data Addresses (16-bit pointers) for Constants\n"
            "//\n"
            "struct SMBDataPointers\n"
            "{\n"
        )
        
        # Address defines
        address_defines = (
            "// Defines for quick access of the addresses within SMBDataPointers\n"
            "//\n\n"
        )
        
        # Constructor defaults
        address_defaults = f"{TAB}SMBDataPointers()\n{TAB}{{\n"
        
        # Data loading code
        loading = "void SMBEngine::loadConstantData()\n{\n"
        
        storage_address = 0x8000
        
        for node in self.root.children:
            if node.type != AstType.AST_LABEL:
                continue
            
            label = node
            label_name = label.value.rstrip(':')  # Remove trailing ':'
            
            # Only process actual data labels, not code labels
            if label.label_type == LabelType.LABEL_DATA:
                print(f"Processing DATA label: {label_name}")
                # Generate constant data
                loading += (
                    f"{TAB}// {label_name}\n"
                    f"{TAB}//\n"
                    f"{TAB}const uint8_t {label_name}_data[] = {{"
                )
                
                list_element = label.child
                byte_count = 0
                
                # Check if we have a list to process
                if not list_element or list_element.type != AstType.AST_LIST:
                    print(f"Skipping {label_name} - no list child found")
                    continue
                
                # Process the list
                current_item = list_element
                while current_item is not None:
                    loading += f"\n{TAB}{TAB}"
                    
                    data_item = current_item.value
                    if not data_item or data_item.type != AstType.AST_DATA8:
                        # Try to move to next item if this isn't data
                        current_item = current_item.next
                        continue
                    
                    # Process the data list
                    data_list_element = data_item.value
                    line_has_data = False
                    while data_list_element is not None:
                        loading += self.translate_expression(data_list_element.value)
                        line_has_data = True
                        
                        if data_list_element.next is not None:
                            loading += ", "
                        
                        byte_count += 1
                        data_list_element = data_list_element.next
                    
                    # Only add comma if we had data and there's more coming
                    if line_has_data and current_item.next is not None:
                        next_item = current_item.next
                        if (next_item and next_item.value and 
                            next_item.value.type == AstType.AST_DATA8):
                            loading += ","
                        elif (next_item and next_item.value and 
                              next_item.value.type == AstType.AST_DATA16):
                            break  # End at data16 (interrupt vectors)
                    
                    # Add comments
                    if data_item.line_number != 0:
                        comment = lookup_comment(data_item.line_number)
                        if comment:
                            loading += f" // {comment[1:]}"  # Strip ';'
                    
                    current_item = current_item.next
                
                if byte_count == 0:
                    # Skip labels with no actual data
                    print(f"Skipping {label_name} - no data bytes found")
                    continue
                
                loading += f"\n{TAB}}};\n"
                loading += f"{TAB}writeData({label_name}, {label_name}_data, sizeof({label_name}_data));\n\n"
                
                # Address declarations
                addresses += f"{TAB}uint16_t {label_name}_ptr;\n"
                address_defines += f"#define {label_name} (dataPointers.{label_name}_ptr)\n"
                address_defaults += f"{TAB}{TAB}this->{label_name}_ptr = 0x{storage_address:x};\n"
                
                storage_address += byte_count
            
            elif label.label_type == LabelType.LABEL_ALIAS:
                # Only create aliases for data labels that alias other data labels
                if self.is_data_alias(label):
                    print(f"Processing DATA ALIAS label: {label_name}")
                    addresses += f"{TAB}uint16_t {label_name}_ptr; // alias\n"
                    address_defines += f"#define {label_name} (dataPointers.{label_name}_ptr)\n"
                    address_defaults += f"{TAB}{TAB}this->{label_name}_ptr = 0x{storage_address:x};\n"
                else:
                    print(f"Skipping CODE ALIAS label: {label_name}")
            else:
                print(f"Skipping CODE label: {label_name}")
        
        # Free space address
        addresses += f"{TAB}uint16_t freeSpaceAddress;\n"
        address_defaults += f"{TAB}{TAB}this->freeSpaceAddress = 0x{storage_address:x};\n"
        
        # Close constructor
        address_defaults += f"{TAB}}}\n"
        addresses += f"\n{address_defaults}}};\n\n"
        
        address_defines += "\n"
        loading += "}\n\n"
        
        # Write to outputs
        self.data_header_output += (
            "#ifndef SMBDATAPOINTERS_HPP\n"
            "#define SMBDATAPOINTERS_HPP\n\n"
            + addresses + address_defines +
            "#endif // SMBDATAPOINTERS_HPP\n"
        )
        
        self.data_output += "#include \"SMB.hpp\"\n\n" + loading
    
    def is_data_alias(self, label_node) -> bool:
        """Check if an alias label points to a data label"""
        # Use first pass classification if available
        label_name = label_node.value.rstrip(':')
        if label_name in self.first_pass_classifications:
            return self.first_pass_classifications[label_name] == LabelType.LABEL_DATA
        
        # Fall back to AST analysis
        child = label_node.child
        if child and child.type == AstType.AST_LABEL:
            return child.label_type == LabelType.LABEL_DATA
        return False
    
    def index_empty_lines(self):
        """Index empty lines in the input file"""
        try:
            with open(self.input_filename, 'r') as file:
                for line_number, line in enumerate(file, 1):
                    if not line.strip():
                        from util import map_newline
                        map_newline(line_number)
        except FileNotFoundError:
            pass  # File not found, skip indexing
    
    def translate(self):
        """Main translation method"""
        # Index empty lines
        self.index_empty_lines()
        
        # Classify labels
        self.classify_labels()
        
        # Add required headers
        self.source_output += "#include \"SMB.hpp\"\n\n"
        
        # Generate outputs
        self.generate_constant_declarations()
        self.generate_data_declarations()
        self.generate_code()
    
    def translate_branch(self, condition: str, destination: str) -> str:
        """Translate a branch instruction"""
        return (
            f"if ({condition})\n"
            f"{TAB}{TAB}goto {destination};"
        )
    
    def translate_expression(self, expr: AstNode) -> str:
        """Translate an expression to C++"""
        if expr is None:
            return ""
        
        if expr.type == AstType.AST_NAME:
            return expr.value
        elif expr.type == AstType.AST_CONST:
            const_val = expr.value
            if const_val.startswith('$'):
                return f"0x{const_val[1:]}"
            elif const_val.startswith('%'):
                return f"0b{const_val[1:]}"
            else:
                return const_val
        elif expr.type == AstType.AST_IMMEDIATE:
            return self.translate_expression(expr.child)
        elif expr.type == AstType.AST_ADD:
            return f"{self.translate_expression(expr.lhs)} + {self.translate_expression(expr.rhs)}"
        elif expr.type == AstType.AST_SUBTRACT:
            return f"{self.translate_expression(expr.lhs)} - {self.translate_expression(expr.rhs)}"
        elif expr.type == AstType.AST_HIBYTE:
            return f"HIBYTE({self.translate_expression(expr.child)})"
        elif expr.type == AstType.AST_LOBYTE:
            return f"LOBYTE({self.translate_expression(expr.child)})"
        elif expr.type == AstType.AST_INDIRECT:
            return f"M({self.translate_expression(expr.child)})"
        elif expr.type == AstType.AST_INDEXED_X:
            return f"{self.translate_expression(expr.child)} + x"
        elif expr.type == AstType.AST_INDEXED_Y:
            child = expr.child
            if child.type == AstType.AST_INDIRECT:
                return f"W({self.translate_expression(child.child)}) + y"
            else:
                return f"{self.translate_expression(child)} + y"
        else:
            raise ValueError(f"Unknown expression type: {expr.type}")
    
    def translate_instruction(self, inst: InstructionNode) -> str:
        """Translate a 6502 instruction to C++"""
        code = inst.code
        
        # Load instructions
        if code == TokenType.LDA.value:
            return f"a = {self.translate_operand(inst.value)};"
        elif code == TokenType.LDX.value:
            return f"x = {self.translate_operand(inst.value)};"
        elif code == TokenType.LDY.value:
            return f"y = {self.translate_operand(inst.value)};"
        
        # Store instructions
        elif code == TokenType.STA.value:
            return f"writeData({self.translate_expression(inst.value)}, a);"
        elif code == TokenType.STX.value:
            return f"writeData({self.translate_expression(inst.value)}, x);"
        elif code == TokenType.STY.value:
            return f"writeData({self.translate_expression(inst.value)}, y);"
        
        # Transfer instructions
        elif code == TokenType.TAX.value:
            return "x = a;"
        elif code == TokenType.TAY.value:
            return "y = a;"
        elif code == TokenType.TXA.value:
            return "a = x;"
        elif code == TokenType.TYA.value:
            return "a = y;"
        elif code == TokenType.TSX.value:
            return "x = s;"
        elif code == TokenType.TXS.value:
            return "s = x;"
        
        # Stack instructions
        elif code == TokenType.PHA.value:
            return "pha();"
        elif code == TokenType.PHP.value:
            return "php();"
        elif code == TokenType.PLA.value:
            return "pla();"
        elif code == TokenType.PLP.value:
            return "plp();"
        
        # Logical instructions
        elif code == TokenType.AND.value:
            return f"a &= {self.translate_operand(inst.value)};"
        elif code == TokenType.EOR.value:
            return f"a ^= {self.translate_operand(inst.value)};"
        elif code == TokenType.ORA.value:
            return f"a |= {self.translate_operand(inst.value)};"
        elif code == TokenType.BIT.value:
            return f"bit({self.translate_operand(inst.value)});"
        
        # Arithmetic instructions
        elif code == TokenType.ADC.value:
            return f"a += {self.translate_operand(inst.value)};"
        elif code == TokenType.SBC.value:
            return f"a -= {self.translate_operand(inst.value)};"
        
        # Compare instructions
        elif code == TokenType.CMP.value:
            return f"compare(a, {self.translate_operand(inst.value)});"
        elif code == TokenType.CPX.value:
            return f"compare(x, {self.translate_operand(inst.value)});"
        elif code == TokenType.CPY.value:
            return f"compare(y, {self.translate_operand(inst.value)});"
        
        # Increment/decrement
        elif code == TokenType.INC.value:
            return f"++{self.translate_operand(inst.value)};"
        elif code == TokenType.INX.value:
            return "++x;"
        elif code == TokenType.INY.value:
            return "++y;"
        elif code == TokenType.DEC.value:
            return f"--{self.translate_operand(inst.value)};"
        elif code == TokenType.DEX.value:
            return "--x;"
        elif code == TokenType.DEY.value:
            return "--y;"
        
        # Shift instructions with proper flag handling
        elif code == TokenType.ASL.value:
            if inst.value:
                return f"{self.translate_operand(inst.value)} <<= 1;"
            else:
                return "a <<= 1;"
        elif code == TokenType.LSR.value:
            if inst.value:
                return f"{self.translate_operand(inst.value)} >>= 1;"
            else:
                return "a >>= 1;"
        elif code == TokenType.ROL.value:
            if inst.value:
                return f"{self.translate_operand(inst.value)}.rol();"
            else:
                return "a.rol();"
        elif code == TokenType.ROR.value:
            if inst.value:
                return f"{self.translate_operand(inst.value)}.ror();"
            else:
                return "a.ror();"
        
        # Jump instructions
        elif code == TokenType.JMP.value:
            if hasattr(inst.value, 'type') and inst.value.type == AstType.AST_NAME:
                if inst.value.value == "EndlessLoop":
                    return "return;"
                else:
                    return f"goto {self.translate_expression(inst.value)};"
            return "/* jmp (complex) */"
        
        elif code == TokenType.JSR.value:
            if inst.value == "JumpEngine":
                # Generate switch-case jump table
                # This is a special case that needs to look at following data
                list_element = inst.parent
                if list_element and hasattr(list_element, 'next'):
                    result = f"switch (a)\n{TAB}{{\n"
                    
                    # Process following .dw entries
                    next_elem = list_element.next
                    index = 0
                    while next_elem is not None:
                        if (next_elem.value.type == AstType.AST_DATA16 and 
                            hasattr(next_elem.value, 'value') and 
                            next_elem.value.value):
                            # Extract label name from data
                            data_list = next_elem.value.value
                            if data_list and hasattr(data_list, 'value'):
                                label_name = self.translate_expression(data_list.value)
                                result += f"{TAB}case {index}:\n"
                                result += f"{TAB}{TAB}goto {label_name};"
                                
                                # Add comment if available
                                if next_elem.value.line_number != 0:
                                    comment = lookup_comment(next_elem.value.line_number)
                                    if comment:
                                        result += f" // {comment[1:]}"  # Strip ';'
                                
                                result += "\n"
                                index += 1
                        else:
                            break
                        next_elem = next_elem.next
                    
                    result += f"{TAB}}}"
                    return result
                else:
                    return f"switch (a) {{ /* JumpEngine entries */ }}"
            else:
                # Regular JSR with return label
                return_label = f"Return_{self.return_label_index}"
                result = f"pushReturnIndex({self.return_label_index});\n{TAB}goto {inst.value};\n{return_label}:"
                self.return_label_index += 1
                return result
        
        elif code == TokenType.RTS.value:
            return "goto Return;"
        
        # Branch instructions
        elif code == TokenType.BCC.value:
            return self.translate_branch("!c", inst.value)
        elif code == TokenType.BCS.value:
            return self.translate_branch("c", inst.value)
        elif code == TokenType.BEQ.value:
            return self.translate_branch("z", inst.value)
        elif code == TokenType.BMI.value:
            return self.translate_branch("n", inst.value)
        elif code == TokenType.BNE.value:
            return self.translate_branch("!z", inst.value)
        elif code == TokenType.BPL.value:
            return self.translate_branch("!n", inst.value)
        elif code == TokenType.BVC.value:
            raise NotImplementedError("BVC instruction not implemented")
        elif code == TokenType.BVS.value:
            raise NotImplementedError("BVS instruction not implemented")
        
        # Flag instructions
        elif code == TokenType.CLC.value:
            return "c = 0;"
        elif code == TokenType.CLD.value:
            return "/* cld */"
        elif code == TokenType.CLI.value:
            raise NotImplementedError("CLI instruction not implemented")
        elif code == TokenType.CLV.value:
            raise NotImplementedError("CLV instruction not implemented")
        elif code == TokenType.SEC.value:
            return "c = 1;"
        elif code == TokenType.SED.value:
            return "d = 1;"  # Set decimal flag
        elif code == TokenType.SEI.value:
            return "/* sei */"
        
        # System instructions
        elif code == TokenType.BRK.value:
            return "return;"
        elif code == TokenType.NOP.value:
            return "; // nop"
        elif code == TokenType.RTI.value:
            return "return;"
        
        else:
            raise ValueError(f"Unknown instruction code: {code}")
    
    def translate_operand(self, operand: AstNode) -> str:
        """Translate an instruction operand"""
        if operand is None:
            return ""
        
        # If not immediate addressing, read from memory
        if operand.type != AstType.AST_IMMEDIATE:
            return f"M({self.translate_expression(operand)})"
        else:
            return self.translate_expression(operand)
    
    def translate_ppu_read(self, operand: AstNode) -> str:
        """Handle special PPU status register reads"""
        expr = self.translate_expression(operand)
        if expr == "PPU_STATUS":
            return "M(PPU_STATUS)"  # This will trigger flip-flop reset
        return f"M({expr})"
